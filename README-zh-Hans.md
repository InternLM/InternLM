# InternLM

<div align="center">

<img src="./doc/imgs/logo.svg" width="200"/>
  <div>&nbsp;</div>
  <div align="center">
    <b><font size="5">ä¹¦ç”ŸÂ·æµ¦è¯­ å®˜ç½‘</font></b>
    <sup>
      <a href="https://internlm.intern-ai.org.cn/">
        <i><font size="4">HOT</font></i>
      </a>
    </sup>
    <div>&nbsp;</div>
  </div>

[![license](./doc/imgs/license.svg)](https://github.com/open-mmlab/mmdetection/blob/main/LICENSE)
[![evaluation](./doc/imgs/compass_support.svg)](https://github.com/internLM/OpenCompass/)
[![Documentation Status](https://readthedocs.org/projects/internlm/badge/?version=latest)](https://internlm.readthedocs.io/zh_CN/latest/?badge=latest)

[ğŸ“˜ä½¿ç”¨æ–‡æ¡£](./doc/usage.md) |
[ğŸ› ï¸å®‰è£…æ•™ç¨‹](./doc/install.md) |
[ğŸ“Šè®­ç»ƒæ€§èƒ½](./doc/train_performance.md) |
[ğŸ‘€æ¨¡å‹åº“](#model-zoo) |
[ğŸ¤—HuggingFace](https://huggingface.co/spaces/internlm/InternLM-Chat-7B) |
[ğŸ†•Update News](./CHANGE_LOG.md) |
[ğŸ¤”Reporting Issues](https://github.com/InternLM/InternLM/issues/new)

[English](./README.md) |
[ç®€ä½“ä¸­æ–‡](./README-zh-Hans.md) |
[æ—¥æœ¬èª](./README-ja-JP.md)

</div>

<p align="center">
    ğŸ‘‹ åŠ å…¥æˆ‘ä»¬çš„ <a href="https://discord.gg/xa29JuW87d" target="_blank">Discord</a> å’Œ <a href="https://github.com/InternLM/InternLM/assets/25839884/a6aad896-7232-4220-ac84-9e070c2633ce" target="_blank">å¾®ä¿¡ç¤¾åŒº</a>
</p>

## ç®€ä»‹

InternLM æ˜¯ä¸€ä¸ªå¼€æºçš„è½»é‡çº§è®­ç»ƒæ¡†æ¶ï¼Œæ—¨åœ¨æ”¯æŒå¤§æ¨¡å‹è®­ç»ƒè€Œæ— éœ€å¤§é‡çš„ä¾èµ–ã€‚é€šè¿‡å•ä¸€çš„ä»£ç åº“ï¼Œå®ƒæ”¯æŒåœ¨æ‹¥æœ‰æ•°åƒä¸ª GPU çš„å¤§å‹é›†ç¾¤ä¸Šè¿›è¡Œé¢„è®­ç»ƒï¼Œå¹¶åœ¨å•ä¸ª GPU ä¸Šè¿›è¡Œå¾®è°ƒï¼ŒåŒæ—¶å®ç°äº†å“è¶Šçš„æ€§èƒ½ä¼˜åŒ–ã€‚åœ¨1024ä¸ª GPU ä¸Šè®­ç»ƒæ—¶ï¼ŒInternLM å¯ä»¥å®ç°è¿‘90%çš„åŠ é€Ÿæ•ˆç‡ã€‚

åŸºäºInternLMè®­ç»ƒæ¡†æ¶ï¼Œæˆ‘ä»¬å·²ç»å‘å¸ƒäº†ä¸¤ä¸ªå¼€æºçš„é¢„è®­ç»ƒæ¨¡å‹ï¼šInternLM-7B å’Œ InternLM-20Bã€‚

## æ›´æ–°

[20230920] InternLM-20B å·²å‘å¸ƒï¼ŒåŒ…æ‹¬åŸºç¡€ç‰ˆå’Œå¯¹è¯ç‰ˆã€‚  
[20230822] InternLM-7B-Chat v1.1 å·²å‘å¸ƒï¼Œå¢åŠ äº†ä»£ç è§£é‡Šå™¨å’Œå‡½æ•°è°ƒç”¨èƒ½åŠ›ã€‚æ‚¨å¯ä»¥ä½¿ç”¨ [Lagent](https://github.com/InternLM/lagent) è¿›è¡Œå°è¯•ã€‚


## Model Zoo

æˆ‘ä»¬çš„æ¨¡å‹åœ¨ä¸‰ä¸ªå¹³å°ä¸Šå‘å¸ƒï¼šTransformersã€ModelScope å’Œ OpenXLabã€‚

| Model                     | Transformers                        | ModelScope                                                                                                                        | OpenXLab                                                                              |å‘å¸ƒæ—¥æœŸ |
|---------------------------|------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------|--------------|
| **InternLM Chat 20B**     | [ğŸ¤—internlm/internlm-chat-20b](https://huggingface.co/internlm/internlm-20b-chat)         | [<img src="./doc/imgs/modelscope_logo.png" width="20px" /> Shanghai_AI_Laboratory/internlm-chat-20b](https://modelscope.cn/models/Shanghai_AI_Laboratory/internlm-20b-chat/summary)         | [![Open in OpenXLab](https://cdn-static.openxlab.org.cn/header/openxlab_models.svg)](https://openxlab.org.cn/models/detail/OpenLMLab/InternLM-chat-20b)     | 2023-09-20   |
| **InternLM 20B**          | [ğŸ¤—internlm/internlm-20b](https://huggingface.co/internlm/internlm-20b)                   | [<img src="./doc/imgs/modelscope_logo.png" width="20px" /> Shanghai_AI_Laboratory/internlm-20b](https://modelscope.cn/models/Shanghai_AI_Laboratory/internlm-20b/summary)                   | [![Open in OpenXLab](https://cdn-static.openxlab.org.cn/header/openxlab_models.svg)](https://openxlab.org.cn/models/detail/OpenLMLab/InternLM-20b)          | 2023-09-20   |
| **InternLM Chat 7B v1.1** | [ğŸ¤—internlm/internlm-chat-7b-v1.1](https://huggingface.co/internlm/internlm-chat-7b-v1.1) | [<img src="./doc/imgs/modelscope_logo.png" width="20px" /> Shanghai_AI_Laboratory/internlm-chat-7b-v1_1](https://modelscope.cn/models/Shanghai_AI_Laboratory/internlm-chat-7b-v1_1/summary) | [![Open in OpenXLab](https://cdn-static.openxlab.org.cn/header/openxlab_models.svg)](https://openxlab.org.cn/models/detail/OpenLMLab/InternLM-chat-7b-v1.1) | 2023-08-22   |
| **InternLM 7B**           | [ğŸ¤—internlm/internlm-7b](https://huggingface.co/internlm/internlm-7b)                     | [<img src="./doc/imgs/modelscope_logo.png" width="20px" /> Shanghai_AI_Laboratory/internlm-7b](https://modelscope.cn/models/Shanghai_AI_Laboratory/internlm-7b/summary)                     | [![Open in OpenXLab](https://cdn-static.openxlab.org.cn/header/openxlab_models.svg)](https://openxlab.org.cn/models/detail/OpenLMLab/InternLM-7b)           | 2023-07-06   |
| **InternLM Chat 7B**      | [ğŸ¤—internlm/internlm-chat-7b](https://huggingface.co/internlm/internlm-chat-7b)           | [<img src="./doc/imgs/modelscope_logo.png" width="20px" /> Shanghai_AI_Laboratory/internlm-chat-7b](https://modelscope.cn/models/Shanghai_AI_Laboratory/internlm-chat-7b/summary)           | [![Open in OpenXLab](https://cdn-static.openxlab.org.cn/header/openxlab_models.svg)](https://openxlab.org.cn/models/detail/OpenLMLab/InternLM-chat-7b)      | 2023-07-06   |
| **InternLM Chat 7B 8k**   | [ğŸ¤—internlm/internlm-chat-7b-8k](https://huggingface.co/internlm/internlm-chat-7b-8k)     | [<img src="./doc/imgs/modelscope_logo.png" width="20px" /> Shanghai_AI_Laboratory/internlm-chat-7b-8k](https://modelscope.cn/models/Shanghai_AI_Laboratory/internlm-chat-7b-8k/summary)     | [![Open in OpenXLab](https://cdn-static.openxlab.org.cn/header/openxlab_models.svg)](https://openxlab.org.cn/models/detail/OpenLMLab/InternLM-chat-7b-8k)   | 2023-07-06   |


<details> 
<summary> InternLM-20B </summary>

#### ç®€ä»‹
InternLM-20B åœ¨è¶…è¿‡ **2.3T** Tokens åŒ…å«é«˜è´¨é‡è‹±æ–‡ã€ä¸­æ–‡å’Œä»£ç çš„æ•°æ®ä¸Šè¿›è¡Œé¢„è®­ç»ƒï¼Œå…¶ä¸­ Chat ç‰ˆæœ¬è¿˜ç»è¿‡äº† SFT å’Œ RLHF è®­ç»ƒï¼Œä½¿å…¶èƒ½å¤Ÿæ›´å¥½ã€æ›´å®‰å…¨åœ°æ»¡è¶³ç”¨æˆ·çš„éœ€æ±‚ã€‚  

InternLM 20B åœ¨æ¨¡å‹ç»“æ„ä¸Šé€‰æ‹©äº†æ·±ç»“æ„ï¼ŒInternLM-20B çš„å±‚æ•°è®¾å®šä¸º60å±‚ï¼Œè¶…è¿‡å¸¸è§„7Bå’Œ13Bæ¨¡å‹æ‰€ä½¿ç”¨çš„32å±‚æˆ–è€…40å±‚ã€‚åœ¨å‚æ•°å—é™çš„æƒ…å†µä¸‹ï¼Œæé«˜å±‚æ•°æœ‰åˆ©äºæé«˜æ¨¡å‹çš„ç»¼åˆèƒ½åŠ›ã€‚æ­¤å¤–ï¼Œç›¸è¾ƒäºInternLM-7Bï¼ŒInternLM-20Bä½¿ç”¨çš„é¢„è®­ç»ƒæ•°æ®ç»è¿‡äº†æ›´é«˜è´¨é‡çš„æ¸…æ´—ï¼Œå¹¶è¡¥å……äº†é«˜çŸ¥è¯†å¯†åº¦å’Œç”¨äºå¼ºåŒ–ç†è§£å’Œæ¨ç†èƒ½åŠ›çš„è®­ç»ƒæ•°æ®ã€‚å› æ­¤ï¼Œå®ƒåœ¨ç†è§£èƒ½åŠ›ã€æ¨ç†èƒ½åŠ›ã€æ•°å­¦èƒ½åŠ›ã€ç¼–ç¨‹èƒ½åŠ›ç­‰è€ƒéªŒè¯­è¨€æ¨¡å‹æŠ€æœ¯æ°´å¹³çš„æ–¹é¢éƒ½å¾—åˆ°äº†æ˜¾è‘—æå‡ã€‚æ€»ä½“è€Œè¨€ï¼ŒInternLM-20Bå…·æœ‰ä»¥ä¸‹çš„ç‰¹ç‚¹ï¼š 
- ä¼˜å¼‚çš„ç»¼åˆæ€§èƒ½
- å¾ˆå¼ºçš„å·¥å…·è°ƒç”¨åŠŸèƒ½
- æ”¯æŒ16kè¯­å¢ƒé•¿åº¦ï¼ˆé€šè¿‡æ¨ç†æ—¶å¤–æ¨ï¼‰
- æ›´å¥½çš„ä»·å€¼å¯¹é½

#### æ€§èƒ½å¯¹æ¯”

åœ¨OpenCompassæå‡ºçš„5ä¸ªèƒ½åŠ›ç»´åº¦ä¸Šï¼ŒInternLM-20Béƒ½å–å¾—å¾ˆå¥½çš„æ•ˆæœï¼ˆç²—ä½“ä¸º13B-33Bè¿™ä¸ªé‡çº§èŒƒå›´å†…ï¼Œå„é¡¹æœ€ä½³æˆç»©ï¼‰

| èƒ½åŠ›ç»´åº¦ | Llama-13B | Llama2-13B | Baichuan2-13B | InternLM-20B | Llama-33B | Llama-65B | Llama2-70B |
|----------|-----------|------------|---------------|--------------|-----------|-----------|------------|
| è¯­è¨€     | 42.5      | 47         | 47.5          | **55**           | 44.6      | 47.1      | 51.6       |
| çŸ¥è¯†     | 58.2      | 58.3       | 48.9          | 60.1         | **64**        | 66        | 67.7       |
| ç†è§£     | 45.5      | 50.9       | 58.1          | **67.3**         | 50.6      | 54.2      | 60.8       |
| æ¨ç†     | 42.7      | 43.6       | 44.2          | **54.9**         | 46.4      | 49.8      | 55         |
| å­¦ç§‘     | 37.3      | 45.2       | 51.8          | **62.5**         | 47.4      | 49.7      | 57.3       |
| æ€»å¹³å‡   | 43.8      | 47.3       | 49.4          | **59.2**         | 48.9      | 51.9      | 57.4       |

ä¸‹è¡¨åœ¨ä¸€äº›æœ‰é‡è¦å½±å“åŠ›çš„å…¸å‹æ•°æ®é›†ä¸Šæ¯”è¾ƒäº†ä¸»æµå¼€æºæ¨¡å‹çš„è¡¨ç°

|      | è¯„æµ‹é›†           | Llama-13B | Llama2-13B | Baichuan2-13B | InternLM-20B | Llama-33B | Llama-65B | Llama2-70B |
|------|------------------|-----------|------------|---------------|--------------|-----------|-----------|------------|
| å­¦ç§‘ | MMLU             | 47.73     | 54.99      | 59.55         | **62.05**        | 58.73     | 63.71     | 69.75      |
|      | C-Eval (val)     | 31.83     | 41.4       | **59.01**         | 58.8         | 37.47     | 40.36     | 50.13      |
|      | AGI-Eval         | 22.03     | 30.93      | 37.37         | **44.58**        | 33.53     | 33.92     | 40.02      |
| çŸ¥è¯† | BoolQ            | 78.75     | 82.42      | 67            | **87.46**        | 84.43     | 86.61     | 87.74      |
|      | TriviaQA         | 52.47     | 59.36      | 46.61         | 57.26        | **66.24**     | 69.79     | 70.71      |
|      | NaturalQuestions | 20.17     | 24.85      | 16.32         | 25.15        | **30.89**     | 33.41     | 34.16      |
| ç†è§£ | CMRC             | 9.26      | 31.59      | 29.85         | **68.78**        | 14.17     | 34.73     | 43.74      |
|      | CSL              | 55        | 58.75      | 63.12         | **65.62**        | 57.5      | 59.38     | 60         |
|      | RACE (middle)    | 53.41     | 63.02      | 68.94         | **86.35**        | 64.55     | 72.35     | 81.55      |
|      | RACE (high)      | 47.63     | 58.86      | 67.18         | **83.28**        | 62.61     | 68.01     | 79.93      |
|      | XSum             | 20.37     | 23.37      | 25.23         | **35.54**        | 20.55     | 19.91     | 25.38      |
| æ¨ç† | WinoGrande       | 64.64     | 64.01      | 67.32         | **69.38**        | 66.85     | 69.38     | 69.77      |
|      | BBH              | 37.93     | 45.62      | 48.98         | **52.51**        | 49.98     | 58.38     | 64.91      |
|      | GSM8K            | 20.32     | 29.57      | **52.62**         | **52.62**        | 42.3      | 54.44     | 63.31      |
|      | PIQA             | 79.71     | 79.76      | 78.07         | 80.25        | **81.34**     | 82.15     | 82.54      |
| ç¼–ç¨‹ | HumanEval        | 14.02     | 18.9       | 17.07         | **25.61**        | 17.68     | 18.9      | 26.22      |
|      | MBPP             | 20.6      | 26.8       | 30.8          | **35.6**         | 28.4      | 33.6      | 39.6       |

æ€»ä½“è€Œè¨€ï¼ŒInternLM-20B åœ¨ç»¼åˆèƒ½åŠ›ä¸Šå…¨é¢é¢†å…ˆäº13Bé‡çº§çš„å¼€æºæ¨¡å‹ï¼ŒåŒæ—¶åœ¨æ¨ç†è¯„æµ‹é›†ä¸Šæ¥è¿‘ç”šè‡³è¶…è¶ŠLlama-65Bçš„æ€§èƒ½ã€‚

- è¯„ä¼°ç»“æœæ¥è‡ª [OpenCompass 20230920](https://github.com/internLM/OpenCompass/)ã€‚
- ç”±äº [OpenCompass](https://github.com/internLM/OpenCompass/) çš„ç‰ˆæœ¬è¿­ä»£ï¼Œè¯„ä¼°æ•°æ®å¯èƒ½å­˜åœ¨æ•°å€¼ä¸Šçš„å·®å¼‚ï¼Œæ‰€ä»¥è¯·å‚è€ƒ [OpenCompass](https://github.com/internLM/OpenCompass/) çš„æœ€æ–°è¯„ä¼°ç»“æœã€‚

</details>


<details> 
<summary> InternLM-7B </summary>

#### æ¨¡å‹æ›´æ–°
[20230822] é€šè¿‡ä½¿ç”¨æ›´ä¸°å¯Œçš„SFTç±»å‹æ•°æ®ï¼ŒInternLM-7B-Chat v1.1æ¨¡å‹æ”¯æŒä»£ç è§£é‡Šå’Œå‡½æ•°è°ƒç”¨ã€‚æ¨¡å‹ç»“æ„ä¸ä»£ç æ²¡æœ‰ä»»ä½•å˜åŒ–ï¼Œå› æ­¤å¯ä»¥ä½¿ç”¨ä¸InternLM-7B-Chatå®Œå…¨ä¸€æ ·çš„æ–¹å¼ä½¿ç”¨æ›´å¼ºå¤§çš„InternLM-7B-Chat v1.1ã€‚

#### ç®€ä»‹
InternLM-7B åŒ…å«äº†ä¸€ä¸ªæ‹¥æœ‰70äº¿å‚æ•°çš„åŸºç¡€æ¨¡å‹å’Œä¸€ä¸ªä¸ºå®é™…åœºæ™¯é‡èº«å®šåˆ¶çš„å¯¹è¯æ¨¡å‹ã€‚è¯¥æ¨¡å‹å…·æœ‰ä»¥ä¸‹ç‰¹ç‚¹ï¼š

- å®ƒåˆ©ç”¨æ•°ä¸‡äº¿çš„é«˜è´¨é‡ä»¤ç‰Œè¿›è¡Œè®­ç»ƒï¼Œå»ºç«‹äº†ä¸€ä¸ªå¼ºå¤§çš„çŸ¥è¯†åº“ã€‚
- å®ƒæ”¯æŒ8kçš„ä¸Šä¸‹æ–‡çª—å£é•¿åº¦ï¼Œä½¿å¾—è¾“å…¥åºåˆ—æ›´é•¿å¹¶å¢å¼ºäº†æ¨ç†èƒ½åŠ›ã€‚
- å®ƒä¸ºç”¨æˆ·æä¾›äº†ä¸€ä¸ªå¤šåŠŸèƒ½çš„å·¥å…·é›†ï¼Œä½¿ç”¨æˆ·èƒ½å¤Ÿçµæ´»åœ°æ„å»ºè‡ªå·±çš„å·¥ä½œæµç¨‹ã€‚

#### æ€§èƒ½å¯¹æ¯”

æˆ‘ä»¬ä½¿ç”¨å¼€æºè¯„æµ‹å·¥å…· [OpenCompass](https://github.com/internLM/OpenCompass/) ä»å­¦ç§‘ç»¼åˆèƒ½åŠ›ã€è¯­è¨€èƒ½åŠ›ã€çŸ¥è¯†èƒ½åŠ›ã€æ¨ç†èƒ½åŠ›ã€ç†è§£èƒ½åŠ›äº”å¤§èƒ½åŠ›ç»´åº¦å¯¹InternLMå¼€å±•å…¨é¢è¯„æµ‹ï¼Œéƒ¨åˆ†è¯„æµ‹ç»“æœå¦‚ä¸‹è¡¨æ‰€ç¤ºï¼Œæ¬¢è¿è®¿é—®[OpenCompass æ¦œå•](https://opencompass.org.cn/rank)è·å–æ›´å¤šçš„è¯„æµ‹ç»“æœã€‚

| æ•°æ®é›†\æ¨¡å‹           |  **InternLM-Chat-7B** |  **InternLM-7B**  |  LLaMA-7B | Baichuan-7B | ChatGLM2-6B | Alpaca-7B | Vicuna-7B |
| -------------------- | --------------------- | ---------------- | --------- |  --------- | ------------ | --------- | ---------- |
| C-Eval(Val)          |      53.2             |        53.4       | 24.2      | 42.7       |  50.9       |  28.9     | 31.2     |
| MMLU                 |      50.8             |       51.0        | 35.2*     |  41.5      |  46.0       |  39.7     | 47.3     |
| AGIEval              |      42.5             |       37.6        | 20.8      | 24.6       |  39.0       | 24.1      | 26.4     |
| CommonSenseQA        |      75.2             |      59.5         | 65.0      | 58.8       | 60.0        | 68.7      | 66.7     |
| BUSTM                |      74.3             |       50.6        | 48.5      | 51.3        | 55.0        | 48.8      | 62.5     |
| CLUEWSC              |      78.6             |      59.1         |  50.3     |  52.8     |  59.8     |   50.3    |  52.2     |
| MATH                 |      6.4            |         7.1        |  2.8       | 3.0       | 6.6       |  2.2      | 2.8       |
| GSM8K                |      34.5           |        31.2        | 10.1       | 9.7       | 29.2      |  6.0      | 15.3  |
|  HumanEval           |      14.0           |        10.4        |   14.0     | 9.2       | 9.2       | 9.2       | 11.0  |
| RACE(High)           |      76.3           |        57.4        | 46.9*      | 28.1      | 66.3      | 40.7      | 54.0  |

- ä»¥ä¸Šè¯„æµ‹ç»“æœåŸºäº [OpenCompass 20230706](https://github.com/internLM/OpenCompass/) è·å¾—ï¼ˆéƒ¨åˆ†æ•°æ®æ ‡æ³¨`*`ä»£è¡¨æ•°æ®æ¥è‡ªåŸå§‹è®ºæ–‡ï¼‰ï¼Œå…·ä½“æµ‹è¯•ç»†èŠ‚å¯å‚è§ [OpenCompass](https://github.com/internLM/OpenCompass/) ä¸­æä¾›çš„é…ç½®æ–‡ä»¶ã€‚
- è¯„æµ‹æ•°æ®ä¼šå›  [OpenCompass](https://github.com/internLM/OpenCompass/) çš„ç‰ˆæœ¬è¿­ä»£è€Œå­˜åœ¨æ•°å€¼å·®å¼‚ï¼Œè¯·ä»¥ [OpenCompass](https://github.com/internLM/OpenCompass/) æœ€æ–°ç‰ˆçš„è¯„æµ‹ç»“æœä¸ºä¸»ã€‚



**å±€é™æ€§ï¼š** å°½ç®¡åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æˆ‘ä»¬éå¸¸æ³¨é‡æ¨¡å‹çš„å®‰å…¨æ€§ï¼Œå°½åŠ›ä¿ƒä½¿æ¨¡å‹è¾“å‡ºç¬¦åˆä¼¦ç†å’Œæ³•å¾‹è¦æ±‚çš„æ–‡æœ¬ï¼Œä½†å—é™äºæ¨¡å‹å¤§å°ä»¥åŠæ¦‚ç‡ç”ŸæˆèŒƒå¼ï¼Œæ¨¡å‹å¯èƒ½ä¼šäº§ç”Ÿå„ç§ä¸ç¬¦åˆé¢„æœŸçš„è¾“å‡ºï¼Œä¾‹å¦‚å›å¤å†…å®¹åŒ…å«åè§ã€æ­§è§†ç­‰æœ‰å®³å†…å®¹ï¼Œè¯·å‹¿ä¼ æ’­è¿™äº›å†…å®¹ã€‚ç”±äºä¼ æ’­ä¸è‰¯ä¿¡æ¯å¯¼è‡´çš„ä»»ä½•åæœï¼Œæœ¬é¡¹ç›®ä¸æ‰¿æ‹…è´£ä»»ã€‚

</details>

## ä½¿ç”¨æ¡ˆä¾‹

### é€šè¿‡ Transformers åŠ è½½

é€šè¿‡ä»¥ä¸‹çš„ä»£ç ä» Transformers åŠ è½½ InternLM æ¨¡å‹ ï¼ˆå¯ä¿®æ”¹æ¨¡å‹åç§°æ›¿æ¢ä¸åŒçš„æ¨¡å‹ï¼‰

```python
>>> from transformers import AutoTokenizer, AutoModelForCausalLM
>>> tokenizer = AutoTokenizer.from_pretrained("internlm/internlm-chat-7b", trust_remote_code=True)
>>> model = AutoModelForCausalLM.from_pretrained("internlm/internlm-chat-7b", trust_remote_code=True).cuda()
>>> model = model.eval()
>>> response, history = model.chat(tokenizer, "ä½ å¥½", history=[])
>>> print(response)
ä½ å¥½ï¼æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ
>>> response, history = model.chat(tokenizer, "è¯·æä¾›ä¸‰ä¸ªç®¡ç†æ—¶é—´çš„å»ºè®®ã€‚", history=history)
>>> print(response)
å½“ç„¶å¯ä»¥ï¼ä»¥ä¸‹æ˜¯ä¸‰ä¸ªç®¡ç†æ—¶é—´çš„å»ºè®®ï¼š
1. åˆ¶å®šè®¡åˆ’ï¼šåˆ¶å®šä¸€ä¸ªè¯¦ç»†çš„è®¡åˆ’ï¼ŒåŒ…æ‹¬æ¯å¤©è¦å®Œæˆçš„ä»»åŠ¡å’Œæ´»åŠ¨ã€‚è¿™å°†æœ‰åŠ©äºæ‚¨æ›´å¥½åœ°ç»„ç»‡æ—¶é—´ï¼Œå¹¶ç¡®ä¿æ‚¨èƒ½å¤ŸæŒ‰æ—¶å®Œæˆä»»åŠ¡ã€‚
2. ä¼˜å…ˆçº§ï¼šå°†ä»»åŠ¡æŒ‰ç…§ä¼˜å…ˆçº§æ’åºï¼Œå…ˆå®Œæˆæœ€é‡è¦çš„ä»»åŠ¡ã€‚è¿™å°†ç¡®ä¿æ‚¨èƒ½å¤Ÿåœ¨æœ€çŸ­çš„æ—¶é—´å†…å®Œæˆæœ€é‡è¦çš„ä»»åŠ¡ï¼Œä»è€ŒèŠ‚çœæ—¶é—´ã€‚
3. é›†ä¸­æ³¨æ„åŠ›ï¼šé¿å…åˆ†å¿ƒï¼Œé›†ä¸­æ³¨æ„åŠ›å®Œæˆä»»åŠ¡ã€‚å…³é—­ç¤¾äº¤åª’ä½“å’Œç”µå­é‚®ä»¶é€šçŸ¥ï¼Œä¸“æ³¨äºä»»åŠ¡ï¼Œè¿™å°†å¸®åŠ©æ‚¨æ›´å¿«åœ°å®Œæˆä»»åŠ¡ï¼Œå¹¶å‡å°‘é”™è¯¯çš„å¯èƒ½æ€§ã€‚
```

### é€šè¿‡ ModelScope åŠ è½½ 

é€šè¿‡ä»¥ä¸‹çš„ä»£ç ä» ModelScope åŠ è½½ InternLM æ¨¡å‹ ï¼ˆå¯ä¿®æ”¹æ¨¡å‹åç§°æ›¿æ¢ä¸åŒçš„æ¨¡å‹ï¼‰

```python
from modelscope import snapshot_download, AutoTokenizer, AutoModelForCausalLM
import torch
model_dir = snapshot_download('Shanghai_AI_Laboratory/internlm-chat-7b-v1_1', revision='v1.0.0')
tokenizer = AutoTokenizer.from_pretrained(model_dir, device_map="auto", trust_remote_code=True,torch_dtype=torch.float16)
model = AutoModelForCausalLM.from_pretrained(model_dir,device_map="auto",  trust_remote_code=True,torch_dtype=torch.float16)
model = model.eval()
response, history = model.chat(tokenizer, "hello", history=[])
print(response)
response, history = model.chat(tokenizer, "please provide three suggestions about time management", history=history)
print(response)
```


### é€šè¿‡å‰ç«¯ç½‘é¡µå¯¹è¯

å¯ä»¥é€šè¿‡ä»¥ä¸‹ä»£ç å¯åŠ¨ä¸€ä¸ªå‰ç«¯çš„ç•Œé¢æ¥ä¸ InternLM Chat 7B æ¨¡å‹è¿›è¡Œäº¤äº’

```bash
pip install streamlit==1.24.0
pip install transformers==4.30.2
streamlit run web_demo.py
```

æ•ˆæœå¦‚ä¸‹

![æ•ˆæœ](https://github.com/InternLM/InternLM/assets/9102141/11b60ee0-47e4-42c0-8278-3051b2f17fe4)

### åŸºäºInternLMé«˜æ€§èƒ½éƒ¨ç½²

æˆ‘ä»¬ä½¿ç”¨ [LMDeploy](https://github.com/InternLM/LMDeploy) å®Œæˆ InternLM çš„ä¸€é”®éƒ¨ç½²ã€‚

1. é¦–å…ˆå®‰è£… LMDeploy:

  ```
  python3 -m pip install lmdeploy
  ```

2. å¿«é€Ÿçš„éƒ¨ç½²å‘½ä»¤å¦‚ä¸‹ï¼š

  ```
  python3 -m lmdeploy.serve.turbomind.deploy InternLM-7B /path/to/internlm-7b/model hf
  ```

3. åœ¨å¯¼å‡ºæ¨¡å‹åï¼Œä½ å¯ä»¥ç›´æ¥é€šè¿‡å¦‚ä¸‹å‘½ä»¤å¯åŠ¨æœåŠ¡ä¸€ä¸ªæœåŠ¡å¹¶å’Œéƒ¨ç½²åçš„æ¨¡å‹å¯¹è¯

  ```
  python3 -m lmdeploy.serve.client {server_ip_addresss}:33337
  ```

[LMDeploy](https://github.com/InternLM/LMDeploy) æ”¯æŒäº† InternLM éƒ¨ç½²çš„å®Œæ•´æµç¨‹ï¼Œè¯·å‚è€ƒ [éƒ¨ç½²æ•™ç¨‹](https://github.com/InternLM/LMDeploy) äº†è§£ InternLM çš„æ›´å¤šéƒ¨ç½²ç»†èŠ‚ã€‚

## å¾®è°ƒ&è®­ç»ƒ

### é¢„è®­ç»ƒä¸å¾®è°ƒä½¿ç”¨æ•™ç¨‹

è¯·å‚è€ƒ[ä½¿ç”¨æ•™ç¨‹](./doc/usage.md)å¼€å§‹InternLMçš„å®‰è£…ã€æ•°æ®å¤„ç†ã€é¢„è®­ç»ƒä¸å¾®è°ƒã€‚

### è½¬æ¢ä¸º Transformers æ ¼å¼ä½¿ç”¨

é€šè¿‡ InternLM è¿›è¡Œè®­ç»ƒçš„æ¨¡å‹å¯ä»¥å¾ˆè½»æ¾åœ°è½¬æ¢ä¸º HuggingFace Transformers æ ¼å¼ï¼Œæ–¹ä¾¿ä¸ç¤¾åŒºå„ç§å¼€æºé¡¹ç›®æ— ç¼å¯¹æ¥ã€‚å€ŸåŠ© `tools/transformers/convert2hf.py` å¯ä»¥å°†è®­ç»ƒä¿å­˜çš„æƒé‡ä¸€é”®è½¬æ¢ä¸º transformers æ ¼å¼

```bash
python tools/transformers/convert2hf.py --src_folder origin_ckpt/ --tgt_folder hf_ckpt/ --tokenizer ./tools/V7_sft.model
```

è½¬æ¢ä¹‹åå¯ä»¥é€šè¿‡ä»¥ä¸‹çš„ä»£ç åŠ è½½ä¸º transformers

```python
>>> from transformers import AutoTokenizer, AutoModel
>>> model = AutoModel.from_pretrained("hf_ckpt/", trust_remote_code=True).cuda()
```

## è®­ç»ƒç³»ç»Ÿ

### ç³»ç»Ÿç»“æ„

è¯·å‚è€ƒ[ç³»ç»Ÿç»“æ„æ–‡æ¡£](./doc/structure.md)è¿›ä¸€æ­¥äº†è§£ã€‚

### è®­ç»ƒæ€§èƒ½

InternLM æ·±åº¦æ•´åˆäº† Flash-Attention, Apex ç­‰é«˜æ€§èƒ½æ¨¡å‹ç®—å­ï¼Œæé«˜äº†è®­ç»ƒæ•ˆç‡ã€‚é€šè¿‡æ„å»º Hybrid Zero æŠ€æœ¯ï¼Œå®ç°è®¡ç®—å’Œé€šä¿¡çš„é«˜æ•ˆé‡å ï¼Œå¤§å¹…é™ä½äº†è®­ç»ƒè¿‡ç¨‹ä¸­çš„è·¨èŠ‚ç‚¹é€šä¿¡æµé‡ã€‚InternLM æ”¯æŒ 7B æ¨¡å‹ä» 8 å¡æ‰©å±•åˆ° 1024 å¡ï¼Œåƒå¡è§„æ¨¡ä¸‹åŠ é€Ÿæ•ˆç‡å¯é«˜è¾¾ 90%ï¼Œè®­ç»ƒååè¶…è¿‡ 180TFLOPSï¼Œå¹³å‡å•å¡æ¯ç§’å¤„ç†çš„ token æ•°é‡è¶…è¿‡3600ã€‚ä¸‹è¡¨ä¸º InternLM åœ¨ä¸åŒé…ç½®ä¸‹çš„æ‰©å±•æ€§æµ‹è¯•æ•°æ®ï¼š

| GPU Number         | 8   | 16  | 32  | 64  | 128  | 256  | 512  | 1024  |
| ---------------- | ---- | ---- | ---- | ---- | ----- | ----- | ----- | ------ |
| TGS | 4078 | 3939 | 3919 | 3944 | 3928  | 3920  | 3835  | 3625   |
| TFLOPS  | 193 | 191  | 188  | 188  | 187   | 185   | 186   | 184    |

TGS ä»£è¡¨å¹³å‡æ¯GPUæ¯ç§’å¯ä»¥å¤„ç†çš„ Token æ•°é‡ã€‚æ›´å¤šçš„æ€§èƒ½æµ‹è¯•æ•°æ®å¯å‚è€ƒ[è®­ç»ƒæ€§èƒ½æ–‡æ¡£](./doc/train_performance.md)è¿›ä¸€æ­¥äº†è§£ã€‚

## è´¡çŒ®

æˆ‘ä»¬æ„Ÿè°¢æ‰€æœ‰çš„è´¡çŒ®è€…ä¸ºæ”¹è¿›å’Œæå‡ InternLM æ‰€ä½œå‡ºçš„åŠªåŠ›ã€‚éå¸¸æ¬¢è¿ç¤¾åŒºç”¨æˆ·èƒ½å‚ä¸è¿›é¡¹ç›®ä¸­æ¥ã€‚è¯·å‚è€ƒè´¡çŒ®æŒ‡å—æ¥äº†è§£å‚ä¸é¡¹ç›®è´¡çŒ®çš„ç›¸å…³æŒ‡å¼•ã€‚

## è‡´è°¢

InternLM ä»£ç åº“æ˜¯ä¸€æ¬¾ç”±ä¸Šæµ·äººå·¥æ™ºèƒ½å®éªŒå®¤å’Œæ¥è‡ªä¸åŒé«˜æ ¡ã€ä¼ä¸šçš„ç ”å‘äººå‘˜å…±åŒå‚ä¸è´¡çŒ®çš„å¼€æºé¡¹ç›®ã€‚æˆ‘ä»¬æ„Ÿè°¢æ‰€æœ‰ä¸ºé¡¹ç›®æä¾›æ–°åŠŸèƒ½æ”¯æŒçš„è´¡çŒ®è€…ï¼Œä»¥åŠæä¾›å®è´µåé¦ˆçš„ç”¨æˆ·ã€‚ æˆ‘ä»¬å¸Œæœ›è¿™ä¸ªå·¥å…·ç®±å’ŒåŸºå‡†æµ‹è¯•å¯ä»¥ä¸ºç¤¾åŒºæä¾›çµæ´»é«˜æ•ˆçš„ä»£ç å·¥å…·ï¼Œä¾›ç”¨æˆ·å¾®è°ƒ InternLM å¹¶å¼€å‘è‡ªå·±çš„æ–°æ¨¡å‹ï¼Œä»è€Œä¸æ–­ä¸ºå¼€æºç¤¾åŒºæä¾›è´¡çŒ®ã€‚ç‰¹åˆ«é¸£è°¢[flash-attention](https://github.com/HazyResearch/flash-attention) ä¸ [ColossalAI](https://github.com/hpcaitech/ColossalAI) ä¸¤é¡¹å¼€æºé¡¹ç›®ã€‚

## å¼€æºè®¸å¯è¯

æœ¬ä»“åº“çš„ä»£ç ä¾ç…§ Apache-2.0 åè®®å¼€æºã€‚æ¨¡å‹æƒé‡å¯¹å­¦æœ¯ç ”ç©¶å®Œå…¨å¼€æ”¾ï¼Œä¹Ÿå¯ç”³è¯·å…è´¹çš„å•†ä¸šä½¿ç”¨æˆæƒï¼ˆ[ç”³è¯·è¡¨](https://wj.qq.com/s2/12725412/f7c1/)ï¼‰ã€‚å…¶ä»–é—®é¢˜ä¸åˆä½œè¯·è”ç³» <internlm@pjlab.org.cn>ã€‚

## å¼•ç”¨

```
@misc{2023internlm,
    title={InternLM: A Multilingual Language Model with Progressively Enhanced Capabilities},
    author={InternLM Team},
    howpublished = {\url{https://github.com/InternLM/InternLM}},
    year={2023}
}
```
