# InternLM

<div align="center">

<img src="./assets//logo.svg" width="200"/>
  <div>&nbsp;</div>
  <div align="center">
    <b><font size="5">ä¹¦ç”ŸÂ·æµ¦è¯­ å®˜ç½‘</font></b>
    <sup>
      <a href="https://internlm.intern-ai.org.cn/">
        <i><font size="4">HOT</font></i>
      </a>
    </sup>
    <div>&nbsp;</div>
  </div>

[![license](./assets//license.svg)](https://github.com/open-mmlab/mmdetection/blob/main/LICENSE)
[![evaluation](./assets//compass_support.svg)](https://github.com/internLM/OpenCompass/)

<!-- [![Documentation Status](https://readthedocs.org/projects/internlm/badge/?version=latest)](https://internlm.readthedocs.io/zh_CN/latest/?badge=latest) -->

[ğŸ“˜å•†ä¸šæˆæƒ](#å¼€æºè®¸å¯è¯) |
[ğŸ¤—HuggingFace](https://huggingface.co/internlm) |
[ğŸ†•æœ€æ–°æ¶ˆæ¯](#æ›´æ–°) |
[ğŸ¤”æäº¤åé¦ˆ](https://github.com/InternLM/InternLM/issues/new)|
[ğŸ“œæŠ€æœ¯æŠ¥å‘Š](https://arxiv.org/abs/2403.17297)<br>
[ğŸ’¬èŠå¤©åº”ç”¨](https://internlm-chat.intern-ai.org.cn/) |
[ğŸ”—API](https://internlm.intern-ai.org.cn/api/document) |
[ğŸ§©é­”ä¹ç¤¾åŒº](https://modelers.cn/spaces/MindSpore-Lab/INTERNLM2-20B-PLAN)

[English](./README.md) |
[ç®€ä½“ä¸­æ–‡](./README_zh-CN.md)

</div>

<p align="center">
    ğŸ‘‹ åŠ å…¥æˆ‘ä»¬çš„ <a href="https://discord.gg/xa29JuW87d" target="_blank">Discord</a> å’Œ <a href="https://github.com/InternLM/InternLM/assets/25839884/a6aad896-7232-4220-ac84-9e070c2633ce" target="_blank">å¾®ä¿¡ç¤¾åŒº</a>
</p>

## ç®€ä»‹

InternLM2.5 ç³»åˆ—æ¨¡å‹åœ¨æœ¬ä»“åº“æ­£å¼å‘å¸ƒï¼Œå…·æœ‰å¦‚ä¸‹ç‰¹æ€§ï¼š

- å“è¶Šçš„æ¨ç†æ€§èƒ½ï¼šåœ¨æ•°å­¦æ¨ç†æ–¹é¢å–å¾—äº†åŒé‡çº§æ¨¡å‹æœ€ä¼˜ç²¾åº¦ï¼Œè¶…è¶Šäº† Llama3 å’Œ Gemma2-9Bã€‚
- æœ‰æ•ˆæ”¯æŒç™¾ä¸‡å­—è¶…é•¿ä¸Šä¸‹æ–‡ï¼šæ¨¡å‹åœ¨ 1 ç™¾ä¸‡å­—é•¿è¾“å…¥ä¸­å‡ ä¹å®Œç¾åœ°å®ç°é•¿æ–‡â€œå¤§æµ·æé’ˆâ€ï¼Œè€Œä¸”åœ¨ LongBench ç­‰é•¿æ–‡ä»»åŠ¡ä¸­çš„è¡¨ç°ä¹Ÿè¾¾åˆ°å¼€æºæ¨¡å‹ä¸­çš„é¢†å…ˆæ°´å¹³ã€‚ å¯ä»¥é€šè¿‡ [LMDeploy](./chat/lmdeploy_zh_cn.md) å°è¯•ç™¾ä¸‡å­—è¶…é•¿ä¸Šä¸‹æ–‡æ¨ç†ã€‚æ›´å¤šå†…å®¹å’Œæ–‡æ¡£å¯¹è¯ demo è¯·æŸ¥çœ‹[è¿™é‡Œ](./long_context/README_zh-CN.md)ã€‚
- å·¥å…·è°ƒç”¨èƒ½åŠ›æ•´ä½“å‡çº§ï¼šInternLM2.5 æ”¯æŒä»ä¸Šç™¾ä¸ªç½‘é¡µæœé›†æœ‰æ•ˆä¿¡æ¯è¿›è¡Œåˆ†ææ¨ç†ï¼Œç›¸å…³å®ç°å°†äºè¿‘æœŸå¼€æºåˆ° [Lagent](https://github.com/InternLM/lagent/tree/main)ã€‚InternLM2.5 å…·æœ‰æ›´å¼ºå’Œæ›´å…·æœ‰æ³›åŒ–æ€§çš„æŒ‡ä»¤ç†è§£ã€å·¥å…·ç­›é€‰ä¸ç»“æœåæ€ç­‰èƒ½åŠ›ï¼Œæ–°ç‰ˆæ¨¡å‹å¯ä»¥æ›´å¯é åœ°æ”¯æŒå¤æ‚æ™ºèƒ½ä½“çš„æ­å»ºï¼Œæ”¯æŒå¯¹å·¥å…·è¿›è¡Œæœ‰æ•ˆçš„å¤šè½®è°ƒç”¨ï¼Œå®Œæˆè¾ƒå¤æ‚çš„ä»»åŠ¡ã€‚å¯ä»¥æŸ¥çœ‹æ›´å¤š[æ ·ä¾‹](./agent/)ã€‚

## æ›´æ–°

\[2024.08.01\] æˆ‘ä»¬å‘å¸ƒäº† InternLM2.5-1.8Bã€InternLM2.5-1.8B-Chatã€InternLM2.5-20B å’Œ InternLM2.5-20B-Chatã€‚å¯ä»¥åœ¨ä¸‹æ–¹çš„ [æ¨¡å‹åº“](#model-zoo) è¿›è¡Œä¸‹è½½ï¼Œæˆ–è€…åœ¨ [model cards](./model_cards/) ä¸­äº†è§£æ›´å¤šç»†èŠ‚ã€‚

\[2024.07.19\] æˆ‘ä»¬å‘å¸ƒäº† 1.8Bã€7B å’Œ 20B å¤§å°çš„ InternLM2-Reward ç³»åˆ—å¥–åŠ±æ¨¡å‹ã€‚å¯ä»¥åœ¨ä¸‹æ–¹çš„ [æ¨¡å‹åº“](#model-zoo) è¿›è¡Œä¸‹è½½ï¼Œæˆ–è€…åœ¨ [model cards](./model_cards/internlm2_reward.md) ä¸­äº†è§£æ›´å¤šç»†èŠ‚ã€‚

\[2024.06.30\] æˆ‘ä»¬å‘å¸ƒäº† InternLM2.5-7Bã€InternLM2.5-7B-Chat å’Œ InternLM2.5-7B-Chat-1Mã€‚å¯ä»¥åœ¨ä¸‹æ–¹çš„ [æ¨¡å‹åº“](#model-zoo) è¿›è¡Œä¸‹è½½ï¼Œæˆ–è€…åœ¨ [model cards](./model_cards/) ä¸­äº†è§£æ›´å¤šç»†èŠ‚ã€‚

\[2024.03.26\] æˆ‘ä»¬å‘å¸ƒäº† InternLM2 çš„æŠ€æœ¯æŠ¥å‘Šã€‚ å¯ä»¥ç‚¹å‡» [arXivé“¾æ¥](https://arxiv.org/abs/2403.17297) æ¥äº†è§£æ›´å¤šç»†èŠ‚ã€‚

\[2024.01.31\] æˆ‘ä»¬å‘å¸ƒäº† InternLM2-1.8Bï¼Œä»¥åŠç›¸å…³çš„å¯¹è¯æ¨¡å‹ã€‚è¯¥æ¨¡å‹åœ¨ä¿æŒé¢†å…ˆæ€§èƒ½çš„æƒ…å†µä¸‹ï¼Œæä¾›äº†æ›´ä½å»‰çš„éƒ¨ç½²æ–¹æ¡ˆã€‚

\[2024.01.23\] æˆ‘ä»¬å‘å¸ƒäº† InternLM2-Math-7B å’Œ InternLM2-Math-20B ä»¥åŠç›¸å…³çš„å¯¹è¯æ¨¡å‹ã€‚InternLM-Mathä»¥è¾ƒå°çš„å°ºå¯¸è¶…è¿‡äº†ChatGPTçš„è¡¨ç°ã€‚å¯ä»¥ç‚¹å‡»[InternLM-Math](https://github.com/InternLM/internlm-math)è¿›è¡Œä¸‹è½½ï¼Œå¹¶äº†è§£è¯¦æƒ…ã€‚

\[2024.01.17\] æˆ‘ä»¬å‘å¸ƒäº† InternLM2-7B å’Œ InternLM2-20B ä»¥åŠç›¸å…³çš„å¯¹è¯æ¨¡å‹ï¼ŒInternLM2 åœ¨æ•°ç†ã€ä»£ç ã€å¯¹è¯ã€åˆ›ä½œç­‰å„æ–¹é¢èƒ½åŠ›éƒ½è·å¾—äº†é•¿è¶³è¿›æ­¥ï¼Œç»¼åˆæ€§èƒ½è¾¾åˆ°å¼€æºæ¨¡å‹çš„é¢†å…ˆæ°´å¹³ã€‚å¯ä»¥ç‚¹å‡»[ä¸‹é¢çš„æ¨¡å‹åº“](#model-zoo)è¿›è¡Œä¸‹è½½æˆ–è€…[æŸ¥çœ‹æ¨¡å‹æ–‡æ¡£](./model_cards/)æ¥äº†è§£æ›´å¤šç»†èŠ‚.

\[2023.12.13\] æˆ‘ä»¬æ›´æ–°äº† InternLM-7B-Chat å’Œ InternLM-20B-Chat æ¨¡å‹æƒé‡ã€‚é€šè¿‡æ”¹è¿›å¾®è°ƒæ•°æ®å’Œè®­ç»ƒç­–ç•¥ï¼Œæ–°ç‰ˆå¯¹è¯æ¨¡å‹ç”Ÿæˆçš„å›å¤è´¨é‡æ›´é«˜ã€è¯­è¨€é£æ ¼æ›´åŠ å¤šå…ƒã€‚

\[2023.09.20\] InternLM-20B å·²å‘å¸ƒï¼ŒåŒ…æ‹¬åŸºç¡€ç‰ˆå’Œå¯¹è¯ç‰ˆã€‚

## Model Zoo

### InternLM2.5

| Model                      | Transformers(HF)                           | ModelScope(HF)                           | OpenXLab(HF)                           | OpenXLab(Origin)                           | Release Date |
| -------------------------- | ------------------------------------------ | ---------------------------------------- | -------------------------------------- | ------------------------------------------ | ------------ |
| **InternLM2.5-1.8B**       | [ğŸ¤—internlm2_5-1_8b](https://huggingface.co/internlm/internlm2_5-1_8b) | [<img src="./assets/modelscope_logo.png" width="20px" /> internlm2_5-1_8b](https://modelscope.cn/models/Shanghai_AI_Laboratory/internlm2_5-1_8b/summary) | [![Open in OpenXLab](https://cdn-static.openxlab.org.cn/header/openxlab_models.svg)](https://openxlab.org.cn/models/detail/OpenLMLab/internlm2_5-1_8b) | [![Open in OpenXLab](https://cdn-static.openxlab.org.cn/header/openxlab_models.svg)](https://openxlab.org.cn/models/detail/OpenLMLab/internlm2_5-1_8b-original) | 2024-08-05   |
| **InternLM2.5-1.8B-Chat**  | [ğŸ¤—internlm2_5-1_8b-chat](https://huggingface.co/internlm/internlm2_5-1_8b-chat) | [<img src="./assets/modelscope_logo.png" width="20px" /> internlm2_5-1_8b](https://modelscope.cn/models/Shanghai_AI_Laboratory/internlm2_5-1_8b-chat/summary) | [![Open in OpenXLab](https://cdn-static.openxlab.org.cn/header/openxlab_models.svg)](https://openxlab.org.cn/models/detail/OpenLMLab/internlm2_5-1_8b-chat) | [![Open in OpenXLab](https://cdn-static.openxlab.org.cn/header/openxlab_models.svg)](https://openxlab.org.cn/models/detail/OpenLMLab/internlm2_5-1_8b-chat-original) | 2024-08-05   |
| **InternLM2.5-7B**         | [ğŸ¤—internlm2_5-7b](https://huggingface.co/internlm/internlm2_5-7b) | [<img src="./assets/modelscope_logo.png" width="20px" /> internlm2_5-7b](https://modelscope.cn/models/Shanghai_AI_Laboratory/internlm2_5-7b/summary) | [![Open in OpenXLab](https://cdn-static.openxlab.org.cn/header/openxlab_models.svg)](https://openxlab.org.cn/models/detail/OpenLMLab/internlm2_5-7b) | [![Open in OpenXLab](https://cdn-static.openxlab.org.cn/header/openxlab_models.svg)](https://openxlab.org.cn/models/detail/OpenLMLab/internlm2_5-7b-original) | 2024-07-03   |
| **InternLM2.5-7B-Chat**    | [ğŸ¤—internlm2_5-7b-chat](https://huggingface.co/internlm/internlm2_5-7b-chat) | [<img src="./assets/modelscope_logo.png" width="20px" /> internlm2_5-7b-chat](https://modelscope.cn/models/Shanghai_AI_Laboratory/internlm2_5-7b-chat/summary) | [![Open in OpenXLab](https://cdn-static.openxlab.org.cn/header/openxlab_models.svg)](https://openxlab.org.cn/models/detail/OpenLMLab/internlm2_5-7b-chat) | [![Open in OpenXLab](https://cdn-static.openxlab.org.cn/header/openxlab_models.svg)](https://openxlab.org.cn/models/detail/OpenLMLab/internlm2_5-7b-chat-original) | 2024-07-03   |
| **InternLM2.5-7B-Chat-1M** | [ğŸ¤—internlm2_5-7b-chat-1m](https://huggingface.co/internlm/internlm2_5-7b-chat-1m) | [<img src="./assets/modelscope_logo.png" width="20px" /> internlm2_5-7b-chat-1m](https://modelscope.cn/models/Shanghai_AI_Laboratory/internlm2_5-7b-chat-1m/summary) | [![Open in OpenXLab](https://cdn-static.openxlab.org.cn/header/openxlab_models.svg)](https://openxlab.org.cn/models/detail/OpenLMLab/internlm2_5-7b-chat-1m) | [![Open in OpenXLab](https://cdn-static.openxlab.org.cn/header/openxlab_models.svg)](https://openxlab.org.cn/models/detail/OpenLMLab/internlm2_5-7b-chat-1m-original) | 2024-07-03   |
| **InternLM2.5-20B**        | [ğŸ¤—internlm2_5-20b](https://huggingface.co/internlm/internlm2_5-20b) | [<img src="./assets/modelscope_logo.png" width="20px" /> internlm2_5-20b](https://modelscope.cn/models/Shanghai_AI_Laboratory/internlm2_5-20b/summary) | [![Open in OpenXLab](https://cdn-static.openxlab.org.cn/header/openxlab_models.svg)](https://openxlab.org.cn/models/detail/OpenLMLab/internlm2_5-20b) | [![Open in OpenXLab](https://cdn-static.openxlab.org.cn/header/openxlab_models.svg)](https://openxlab.org.cn/models/detail/OpenLMLab/internlm2_5-20b-original) | 2024-08-05   |
| **InternLM2.5-20B-Chat**   | [ğŸ¤—internlm2_5-20b-chat](https://huggingface.co/internlm/internlm2_5-20b-chat) | [<img src="./assets/modelscope_logo.png" width="20px" /> internlm2_5-20b](https://modelscope.cn/models/Shanghai_AI_Laboratory/internlm2_5-20b-chat/summary) | [![Open in OpenXLab](https://cdn-static.openxlab.org.cn/header/openxlab_models.svg)](https://openxlab.org.cn/models/detail/OpenLMLab/internlm2_5-20b-chat) | [![Open in OpenXLab](https://cdn-static.openxlab.org.cn/header/openxlab_models.svg)](https://openxlab.org.cn/models/detail/OpenLMLab/internlm2_5-20b-chat-original) | 2024-08-05   |

**æ¨¡å‹è¯´æ˜ï¼š**

ç›®å‰ InternLM 2.5 ç³»åˆ—å‘å¸ƒäº† 1.8Bã€7B å’Œ 20B å¤§å°çš„æ¨¡å‹ã€‚7B ä¸ºè½»é‡çº§çš„ç ”ç©¶å’Œåº”ç”¨æä¾›äº†ä¸€ä¸ªè½»ä¾¿ä½†æ€§èƒ½ä¸ä¿—çš„æ¨¡å‹ï¼Œ20B æ¨¡å‹çš„ç»¼åˆæ€§èƒ½æ›´ä¸ºå¼ºåŠ²ï¼Œå¯ä»¥æœ‰æ•ˆæ”¯æŒæ›´åŠ å¤æ‚çš„å®ç”¨åœºæ™¯ã€‚æ¯ä¸ªè§„æ ¼ä¸åŒæ¨¡å‹å…³ç³»å¦‚ä¸‹æ‰€ç¤ºï¼š

1. **InternLM2.5**ï¼šç»å†äº†å¤§è§„æ¨¡é¢„è®­ç»ƒçš„åŸºåº§æ¨¡å‹ï¼Œæ˜¯æˆ‘ä»¬æ¨èçš„åœ¨å¤§éƒ¨åˆ†åº”ç”¨ä¸­è€ƒè™‘é€‰ç”¨çš„ä¼˜ç§€åŸºåº§ã€‚
2. **InternLM2.5-Chat**: å¯¹è¯æ¨¡å‹ï¼Œåœ¨ InternLM2.5 åŸºåº§ä¸Šç»å†äº†æœ‰ç›‘ç£å¾®è°ƒå’Œ online RLHFã€‚InternLM2.5-Chat é¢å‘å¯¹è¯äº¤äº’è¿›è¡Œäº†ä¼˜åŒ–ï¼Œå…·æœ‰è¾ƒå¥½çš„æŒ‡ä»¤éµå¾ªã€å…±æƒ…èŠå¤©å’Œè°ƒç”¨å·¥å…·ç­‰çš„èƒ½åŠ›ï¼Œæ˜¯æˆ‘ä»¬æ¨èç›´æ¥ç”¨äºä¸‹æ¸¸åº”ç”¨çš„æ¨¡å‹ã€‚
3. **InternLM2.5-Chat-1M**: InternLM2.5-Chat-1M æ”¯æŒä¸€ç™¾ä¸‡å­—è¶…é•¿ä¸Šä¸‹æ–‡ï¼Œå¹¶å…·æœ‰å’Œ InternLM2.5-Chat ç›¸å½“çš„ç»¼åˆæ€§èƒ½è¡¨ç°ã€‚

**å±€é™æ€§ï¼š** å°½ç®¡åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æˆ‘ä»¬éå¸¸æ³¨é‡æ¨¡å‹çš„å®‰å…¨æ€§ï¼Œå°½åŠ›ä¿ƒä½¿æ¨¡å‹è¾“å‡ºç¬¦åˆä¼¦ç†å’Œæ³•å¾‹è¦æ±‚çš„æ–‡æœ¬ï¼Œä½†å—é™äºæ¨¡å‹å¤§å°ä»¥åŠæ¦‚ç‡ç”ŸæˆèŒƒå¼ï¼Œæ¨¡å‹å¯èƒ½ä¼šäº§ç”Ÿå„ç§ä¸ç¬¦åˆé¢„æœŸçš„è¾“å‡ºï¼Œä¾‹å¦‚å›å¤å†…å®¹åŒ…å«åè§ã€æ­§è§†ç­‰æœ‰å®³å†…å®¹ï¼Œè¯·å‹¿ä¼ æ’­è¿™äº›å†…å®¹ã€‚ç”±äºä¼ æ’­ä¸è‰¯ä¿¡æ¯å¯¼è‡´çš„ä»»ä½•åæœï¼Œæœ¬é¡¹ç›®ä¸æ‰¿æ‹…è´£ä»»ã€‚

**è¡¥å……è¯´æ˜ï¼š** ä¸Šè¡¨ä¸­çš„ `HF` è¡¨ç¤ºå¯¹åº”æ¨¡å‹ä¸º HuggingFace å¹³å°æä¾›çš„ [transformers](https://github.com/huggingface/transformers) æ¡†æ¶æ ¼å¼ï¼›`Origin` åˆ™è¡¨ç¤ºå¯¹åº”æ¨¡å‹ä¸ºæˆ‘ä»¬ InternLM å›¢é˜Ÿçš„ [InternEvo](https://github.com/InternLM/InternEvo) æ¡†æ¶æ ¼å¼ã€‚

### InternLM2-Reward

InternLM2-Reward æ˜¯åŸºäº 240 ä¸‡ä¸ªåå¥½æ ·æœ¬è¿›è¡Œè®­ç»ƒçš„å¥–åŠ±æ¨¡å‹ï¼Œæœ‰ 1.8Bã€7B å’Œ 20B å¤§å°å¯ä¾›é€‰æ‹©ã€‚è¿™äº›æ¨¡å‹è¢«ç”¨äº InternLM å¯¹è¯æ¨¡å‹çš„ PPO è®­ç»ƒè¿‡ç¨‹ã€‚è¯·å‚è€ƒ [model cards](./model_cards/internlm2_reward.md) äº†è§£æ›´å¤šç»†èŠ‚ã€‚

| Model                     | RewardBench Score | Transformers(HF)                                   | ModelScope(HF)                                    | OpenXLab(HF)                                    | Release Date |
| ------------------------- | ----------------- | -------------------------------------------------- | ------------------------------------------------- | ----------------------------------------------- | ------------ |
| **InternLM2-1.8B-Reward** | 80.6              | [ğŸ¤—internlm2-1_8b-reward](https://huggingface.co/internlm/internlm2-1_8b-reward) | [<img src="./assets/modelscope_logo.png" width="20px" /> internlm2-1_8b-reward](https://modelscope.cn/models/Shanghai_AI_Laboratory/internlm2-1_8b-reward/summary) | [![Open in OpenXLab](https://cdn-static.openxlab.org.cn/header/openxlab_models.svg)](https://openxlab.org.cn/models/detail/OpenLMLab/internlm2-1_8b-reward) | 2024-07-19   |
| **InternLM2-7B-Reward**   | 86.6              | [ğŸ¤—internlm2-7b-reward](https://huggingface.co/internlm/internlm2-7b-reward) | [<img src="./assets/modelscope_logo.png" width="20px" /> internlm2-7b-reward](https://modelscope.cn/models/Shanghai_AI_Laboratory/internlm2-7b-reward/summary) | [![Open in OpenXLab](https://cdn-static.openxlab.org.cn/header/openxlab_models.svg)](https://openxlab.org.cn/models/detail/OpenLMLab/internlm2-7b-reward) | 2024-07-19   |
| **InternLM2-20B-Reward**  | 89.5              | [ğŸ¤—internlm2-20b-reward](https://huggingface.co/internlm/internlm2-20b-reward) | [<img src="./assets/modelscope_logo.png" width="20px" /> internlm2-20b-reward](https://modelscope.cn/models/Shanghai_AI_Laboratory/internlm2-20b-reward/summary) | [![Open in OpenXLab](https://cdn-static.openxlab.org.cn/header/openxlab_models.svg)](https://openxlab.org.cn/models/detail/OpenLMLab/internlm2-20b-reward) | 2024-07-19   |

### InternLM2

<details>
    <summary>(click to expand)</summary>

æˆ‘ä»¬ä¸Šä¸€ä»£çš„æ¨¡å‹ï¼Œåœ¨é•¿ä¸Šä¸‹æ–‡å¤„ç†ã€æ¨ç†å’Œç¼–ç æ–¹é¢å…·æœ‰ä¼˜ç§€çš„æ€§èƒ½ã€‚è¯·å‚è€ƒ [model cards](./model_cards/) äº†è§£æ›´å¤šç»†èŠ‚ã€‚

| Model                       | Transformers(HF)                          | ModelScope(HF)                           | OpenXLab(HF)                           | OpenXLab(Origin)                           | Release Date |
| --------------------------- | ----------------------------------------- | ---------------------------------------- | -------------------------------------- | ------------------------------------------ | ------------ |
| **InternLM2-1.8B**          | [ğŸ¤—internlm2-1.8b](https://huggingface.co/internlm/internlm2-1_8b) | [<img src="./assets/modelscope_logo.png" width="20px" /> internlm2-1.8b](https://www.modelscope.cn/models/Shanghai_AI_Laboratory/internlm2-1_8b/summary) | [![Open in OpenXLab](https://cdn-static.openxlab.org.cn/header/openxlab_models.svg)](https://openxlab.org.cn/models/detail/OpenLMLab/internlm2-base-1.8b) | [![Open in OpenXLab](https://cdn-static.openxlab.org.cn/header/openxlab_models.svg)](https://openxlab.org.cn/models/detail/OpenLMLab/internlm2-base-1.8b-original) | 2024-01-31   |
| **InternLM2-Chat-1.8B-SFT** | [ğŸ¤—internlm2-chat-1.8b-sft](https://huggingface.co/internlm/internlm2-chat-1_8b-sft) | [<img src="./assets/modelscope_logo.png" width="20px" /> internlm2-chat-1.8b-sft](https://www.modelscope.cn/models/Shanghai_AI_Laboratory/internlm2-chat-1_8b-sft/summary) | [![Open in OpenXLab](https://cdn-static.openxlab.org.cn/header/openxlab_models.svg)](https://openxlab.org.cn/models/detail/OpenLMLab/internlm2-chat-1.8b-sft) | [![Open in OpenXLab](https://cdn-static.openxlab.org.cn/header/openxlab_models.svg)](https://openxlab.org.cn/models/detail/OpenLMLab/internlm2-chat-1.8b-sft-original) | 2024-01-31   |
| **InternLM2-Chat-1.8B**     | [ğŸ¤—internlm2-chat-1.8b](https://huggingface.co/internlm/internlm2-chat-1_8b) | [<img src="./assets/modelscope_logo.png" width="20px" /> internlm2-chat-1.8b](https://www.modelscope.cn/models/Shanghai_AI_Laboratory/internlm2-chat-1_8b/summary) | [![Open in OpenXLab](https://cdn-static.openxlab.org.cn/header/openxlab_models.svg)](https://openxlab.org.cn/models/detail/OpenLMLab/internlm2-chat-1.8b) | [![Open in OpenXLab](https://cdn-static.openxlab.org.cn/header/openxlab_models.svg)](https://openxlab.org.cn/models/detail/OpenLMLab/internlm2-chat-1.8b-original) | 2024-02-19   |
| **InternLM2-Base-7B**       | [ğŸ¤—internlm2-base-7b](https://huggingface.co/internlm/internlm2-base-7b) | [<img src="./assets/modelscope_logo.png" width="20px" /> internlm2-base-7b](https://modelscope.cn/models/Shanghai_AI_Laboratory/internlm2-base-7b/summary) | [![Open in OpenXLab](https://cdn-static.openxlab.org.cn/header/openxlab_models.svg)](https://openxlab.org.cn/models/detail/OpenLMLab/internlm2-base-7b) | [![Open in OpenXLab](https://cdn-static.openxlab.org.cn/header/openxlab_models.svg)](https://openxlab.org.cn/models/detail/OpenLMLab/internlm2-base-7b-original) | 2024-01-17   |
| **InternLM2-7B**            | [ğŸ¤—internlm2-7b](https://huggingface.co/internlm/internlm2-7b) | [<img src="./assets/modelscope_logo.png" width="20px" /> internlm2-7b](https://modelscope.cn/models/Shanghai_AI_Laboratory/internlm2-7b/summary) | [![Open in OpenXLab](https://cdn-static.openxlab.org.cn/header/openxlab_models.svg)](https://openxlab.org.cn/models/detail/OpenLMLab/internlm2-7b) | [![Open in OpenXLab](https://cdn-static.openxlab.org.cn/header/openxlab_models.svg)](https://openxlab.org.cn/models/detail/OpenLMLab/internlm2-7b-original) | 2024-01-17   |
| **InternLM2-Chat-7B-SFT**   | [ğŸ¤—internlm2-chat-7b-sft](https://huggingface.co/internlm/internlm2-chat-7b-sft) | [<img src="./assets/modelscope_logo.png" width="20px" /> internlm2-chat-7b-sft](https://modelscope.cn/models/Shanghai_AI_Laboratory/internlm2-chat-7b-sft/summary) | [![Open in OpenXLab](https://cdn-static.openxlab.org.cn/header/openxlab_models.svg)](https://openxlab.org.cn/models/detail/OpenLMLab/internlm2-chat-7b-sft) | [![Open in OpenXLab](https://cdn-static.openxlab.org.cn/header/openxlab_models.svg)](https://openxlab.org.cn/models/detail/OpenLMLab/internlm2-chat-7b-sft-original) | 2024-01-17   |
| **InternLM2-Chat-7B**       | [ğŸ¤—internlm2-chat-7b](https://huggingface.co/internlm/internlm2-chat-7b) | [<img src="./assets/modelscope_logo.png" width="20px" /> internlm2-chat-7b](https://modelscope.cn/models/Shanghai_AI_Laboratory/internlm2-chat-7b/summary) | [![Open in OpenXLab](https://cdn-static.openxlab.org.cn/header/openxlab_models.svg)](https://openxlab.org.cn/models/detail/OpenLMLab/internlm2-chat-7b) | [![Open in OpenXLab](https://cdn-static.openxlab.org.cn/header/openxlab_models.svg)](https://openxlab.org.cn/models/detail/OpenLMLab/internlm2-chat-7b-original) | 2024-01-17   |
| **InternLM2-Base-20B**      | [ğŸ¤—internlm2-base-20b](https://huggingface.co/internlm/internlm2-base-20b) | [<img src="./assets/modelscope_logo.png" width="20px" /> internlm2-base-20b](https://modelscope.cn/models/Shanghai_AI_Laboratory/internlm2-base-20b/summary) | [![Open in OpenXLab](https://cdn-static.openxlab.org.cn/header/openxlab_models.svg)](https://openxlab.org.cn/models/detail/OpenLMLab/internlm2-base-20b) | [![Open in OpenXLab](https://cdn-static.openxlab.org.cn/header/openxlab_models.svg)](https://openxlab.org.cn/models/detail/OpenLMLab/internlm2-base-20b-original) | 2024-01-17   |
| **InternLM2-20B**           | [ğŸ¤—internlm2-20b](https://huggingface.co/internlm/internlm2-20b) | [<img src="./assets/modelscope_logo.png" width="20px" /> internlm2-20b](https://modelscope.cn/models/Shanghai_AI_Laboratory/internlm2-20b/summary) | [![Open in OpenXLab](https://cdn-static.openxlab.org.cn/header/openxlab_models.svg)](https://openxlab.org.cn/models/detail/OpenLMLab/internlm2-20b) | [![Open in OpenXLab](https://cdn-static.openxlab.org.cn/header/openxlab_models.svg)](https://openxlab.org.cn/models/detail/OpenLMLab/internlm2-20b-original) | 2024-01-17   |
| **InternLM2-Chat-20B-SFT**  | [ğŸ¤—internlm2-chat-20b-sft](https://huggingface.co/internlm/internlm2-chat-20b-sft) | [<img src="./assets/modelscope_logo.png" width="20px" /> internlm2-chat-20b-sft](https://modelscope.cn/models/Shanghai_AI_Laboratory/internlm2-chat-20b-sft/summary) | [![Open in OpenXLab](https://cdn-static.openxlab.org.cn/header/openxlab_models.svg)](https://openxlab.org.cn/models/detail/OpenLMLab/internlm2-chat-20b-sft) | [![Open in OpenXLab](https://cdn-static.openxlab.org.cn/header/openxlab_models.svg)](https://openxlab.org.cn/models/detail/OpenLMLab/internlm2-chat-20b-sft-original) | 2024-01-17   |
| **InternLM2-Chat-20B**      | [ğŸ¤—internlm2-chat-20b](https://huggingface.co/internlm/internlm2-chat-20b) | [<img src="./assets/modelscope_logo.png" width="20px" /> internlm2-chat-20b](https://modelscope.cn/models/Shanghai_AI_Laboratory/internlm2-chat-20b/summary) | [![Open in OpenXLab](https://cdn-static.openxlab.org.cn/header/openxlab_models.svg)](https://openxlab.org.cn/models/detail/OpenLMLab/internlm2-chat-20b) | [![Open in OpenXLab](https://cdn-static.openxlab.org.cn/header/openxlab_models.svg)](https://openxlab.org.cn/models/detail/OpenLMLab/internlm2-chat-20b-original) | 2024-01-17   |

</details>

## æ€§èƒ½

æˆ‘ä»¬ä½¿ç”¨å¼€æºè¯„æµ‹å·¥å…· [OpenCompass](https://github.com/open-compass/opencompass) åœ¨å‡ ä¸ªé‡è¦çš„åŸºå‡†æµ‹è¯•ä¸­å¯¹ InternLM2.5 è¿›è¡Œäº†è¯„æµ‹ã€‚éƒ¨åˆ†è¯„æµ‹ç»“æœå¦‚ä¸‹è¡¨æ‰€ç¤ºã€‚æ¬¢è¿è®¿é—® [OpenCompass æ’è¡Œæ¦œ](https://rank.opencompass.org.cn) è·å–æ›´å¤šè¯„æµ‹ç»“æœã€‚

### åŸºåº§æ¨¡å‹

| Benchmark      | InternLM2.5-7B | Llama3-8B | Yi-1.5-9B |
| -------------- | -------------- | --------- | --------- |
| MMLU (5-shot)  | **71.6**       | 66.4      | 71.6      |
| CMMLU (5-shot) | **79.1**       | 51.0      | 74.1      |
| BBH (3-shot)   | 70.1           | 59.7      | 71.1      |
| MATH (4-shot)  | **34.0**       | 16.4      | 31.9      |
| GSM8K (4-shot) | **74.8**       | 54.3      | 74.5      |
| GPQA (0-shot)  | **31.3**       | 31.3      | 27.8      |

### å¯¹è¯æ¨¡å‹

| Benchmark          | InternLM2.5-7B-Chat | Llama3-8B-Instruct | Gemma2-9B-IT | Yi-1.5-9B-Chat | GLM-4-9B-Chat | Qwen2-7B-Instruct |
| ------------------ | ------------------- | ------------------ | ------------ | -------------- | ------------- | ----------------- |
| MMLU (5-shot)      | **72.8**            | 68.4               | 70.9         | 71.0           | 71.4          | 70.8              |
| CMMLU (5-shot)     | 78.0                | 53.3               | 60.3         | 74.5           | 74.5          | 80.9              |
| BBH (3-shot CoT)   | **71.6**            | 54.4               | 68.2\*       | 69.6           | 69.6          | 65.0              |
| MATH (0-shot CoT)  | **60.1**            | 27.9               | 46.9         | 51.1           | 51.1          | 48.6              |
| GSM8K (0-shot CoT) | 86.0                | 72.9               | 88.9         | 80.1           | 85.3          | 82.9              |
| GPQA (0-shot)      | **38.4**            | 26.1               | 33.8         | 37.9           | 36.9          | 38.4              |

- æˆ‘ä»¬ä½¿ç”¨ `ppl` å¯¹åŸºåº§æ¨¡å‹è¿›è¡Œ MCQ æŒ‡æ ‡çš„è¯„æµ‹ã€‚
- è¯„æµ‹ç»“æœæ¥è‡ª [OpenCompass](https://github.com/open-compass/opencompass) ï¼Œè¯„æµ‹é…ç½®å¯ä»¥åœ¨ [OpenCompass](https://github.com/open-compass/opencompass) æä¾›çš„é…ç½®æ–‡ä»¶ä¸­æ‰¾åˆ°ã€‚
- ç”±äº [OpenCompass](https://github.com/open-compass/opencompass) çš„ç‰ˆæœ¬è¿­ä»£ï¼Œè¯„æµ‹æ•°æ®å¯èƒ½å­˜åœ¨æ•°å€¼å·®å¼‚ï¼Œå› æ­¤è¯·å‚è€ƒ [OpenCompass](https://github.com/open-compass/opencompass) çš„æœ€æ–°è¯„æµ‹ç»“æœã€‚
- \* è¡¨ç¤ºä»åŸè®ºæ–‡ä¸­å¤åˆ¶è€Œæ¥ã€‚

## ä¾èµ–

- Python >= 3.8
- PyTorch >= 1.12.0 (æ¨è 2.0.0 å’Œæ›´é«˜ç‰ˆæœ¬)
- Transformers >= 4.38

## ä½¿ç”¨æ¡ˆä¾‹

InternLM æ”¯æŒä¼—å¤šçŸ¥åçš„ä¸Šä¸‹æ¸¸é¡¹ç›®ï¼Œå¦‚ LLaMA-Factoryã€vLLMã€llama.cpp ç­‰ã€‚è¿™ç§æ”¯æŒä½¿å¾—å¹¿å¤§ç”¨æˆ·ç¾¤ä½“èƒ½å¤Ÿæ›´é«˜æ•ˆã€æ›´æ–¹ä¾¿åœ°ä½¿ç”¨ InternLM å…¨ç³»åˆ—æ¨¡å‹ã€‚ä¸ºæ–¹ä¾¿ä½¿ç”¨ï¼Œæˆ‘ä»¬ä¸ºéƒ¨åˆ†ç”Ÿæ€ç³»ç»Ÿé¡¹ç›®æä¾›äº†æ•™ç¨‹ï¼Œè®¿é—®[æ­¤å¤„](./ecosystem/README_zh-CN.md)å³å¯è·å–ã€‚

æ¥ä¸‹æ¥æˆ‘ä»¬å±•ç¤ºä½¿ç”¨ [Transformers](#import-from-transformers)ï¼Œ[ModelScope](#import-from-modelscope) å’Œ [Web demo](#dialogue) è¿›è¡Œæ¨ç†ã€‚
å¯¹è¯æ¨¡å‹é‡‡ç”¨äº† [chatml æ ¼å¼](./chat/chat_format.md) æ¥æ”¯æŒé€šç”¨å¯¹è¯å’Œæ™ºèƒ½ä½“åº”ç”¨ã€‚
ä¸ºäº†ä¿éšœæ›´å¥½çš„ä½¿ç”¨æ•ˆæœï¼Œåœ¨ç”¨ [Transformers](#import-from-transformers) æˆ– [ModelScope](#import-from-modelscope) è¿›è¡Œæ¨ç†å‰ï¼Œè¯·ç¡®ä¿å®‰è£…çš„ transformers åº“ç‰ˆæœ¬æ»¡è¶³ä»¥ä¸‹è¦æ±‚ï¼š

```
transformers >= 4.38
```

### é€šè¿‡ Transformers åŠ è½½

é€šè¿‡ä»¥ä¸‹çš„ä»£ç ä» Transformers åŠ è½½ InternLM2.5-7B-Chat æ¨¡å‹ ï¼ˆå¯ä¿®æ”¹æ¨¡å‹åç§°æ›¿æ¢ä¸åŒçš„æ¨¡å‹ï¼‰

```python
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM
tokenizer = AutoTokenizer.from_pretrained("internlm/internlm2_5-7b-chat", trust_remote_code=True)
# è®¾ç½®`torch_dtype=torch.float16`æ¥å°†æ¨¡å‹ç²¾åº¦æŒ‡å®šä¸ºtorch.float16ï¼Œå¦åˆ™å¯èƒ½ä¼šå› ä¸ºæ‚¨çš„ç¡¬ä»¶åŸå› é€ æˆæ˜¾å­˜ä¸è¶³çš„é—®é¢˜ã€‚
model = AutoModelForCausalLM.from_pretrained("internlm/internlm2_5-7b-chat", device_map="auto",trust_remote_code=True, torch_dtype=torch.float16)
# (å¯é€‰) å¦‚æœåœ¨ä½èµ„æºè®¾å¤‡ä¸Šï¼Œå¯ä»¥é€šè¿‡bitsandbytesåŠ è½½4-bitæˆ–8-bité‡åŒ–çš„æ¨¡å‹ï¼Œè¿›ä¸€æ­¥èŠ‚çœGPUæ˜¾å­˜.
  # 4-bit é‡åŒ–çš„ InternLM 7B å¤§çº¦ä¼šæ¶ˆè€— 8GB æ˜¾å­˜.
  # pip install -U bitsandbytes
  # 8-bit: model = AutoModelForCausalLM.from_pretrained(model_dir, device_map="auto", trust_remote_code=True, load_in_8bit=True)
  # 4-bit: model = AutoModelForCausalLM.from_pretrained(model_dir, device_map="auto", trust_remote_code=True, load_in_4bit=True)
model = model.eval()
response, history = model.chat(tokenizer, "ä½ å¥½", history=[])
print(response)
# æ¨¡å‹è¾“å‡ºï¼šä½ å¥½ï¼æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ
response, history = model.chat(tokenizer, "è¯·æä¾›ä¸‰ä¸ªç®¡ç†æ—¶é—´çš„å»ºè®®ã€‚", history=history)
print(response)
```

### é€šè¿‡ ModelScope åŠ è½½

é€šè¿‡ä»¥ä¸‹çš„ä»£ç ä» ModelScope åŠ è½½ InternLM2.5-7B-Chat æ¨¡å‹ ï¼ˆå¯ä¿®æ”¹æ¨¡å‹åç§°æ›¿æ¢ä¸åŒçš„æ¨¡å‹ï¼‰

```python
import torch
from modelscope import snapshot_download, AutoTokenizer, AutoModelForCausalLM
model_dir = snapshot_download('Shanghai_AI_Laboratory/internlm2_5-7b-chat')
tokenizer = AutoTokenizer.from_pretrained(model_dir, device_map="auto", trust_remote_code=True)
model = AutoModelForCausalLM.from_pretrained(model_dir, device_map="auto", trust_remote_code=True, torch_dtype=torch.float16)
# (å¯é€‰) å¦‚æœåœ¨ä½èµ„æºè®¾å¤‡ä¸Šï¼Œå¯ä»¥é€šè¿‡bitsandbytesåŠ è½½4-bitæˆ–8-bité‡åŒ–çš„æ¨¡å‹ï¼Œè¿›ä¸€æ­¥èŠ‚çœGPUæ˜¾å­˜.
  # 4-bit é‡åŒ–çš„ InternLM 7B å¤§çº¦ä¼šæ¶ˆè€— 8GB æ˜¾å­˜.
  # pip install -U bitsandbytes
  # 8-bit: model = AutoModelForCausalLM.from_pretrained(model_dir, device_map="auto", trust_remote_code=True, load_in_8bit=True)
  # 4-bit: model = AutoModelForCausalLM.from_pretrained(model_dir, device_map="auto", trust_remote_code=True, load_in_4bit=True)
model = model.eval()
response, history = model.chat(tokenizer, "hello", history=[])
print(response)
response, history = model.chat(tokenizer, "please provide three suggestions about time management", history=history)
print(response)
```

### é€šè¿‡å‰ç«¯ç½‘é¡µå¯¹è¯

å¯ä»¥é€šè¿‡ä»¥ä¸‹ä»£ç å¯åŠ¨ä¸€ä¸ªå‰ç«¯çš„ç•Œé¢æ¥ä¸ InternLM Chat 7B æ¨¡å‹è¿›è¡Œäº¤äº’

```bash
pip install streamlit
pip install transformers>=4.38
streamlit run ./chat/web_demo.py
```

## InternLM é«˜æ€§èƒ½éƒ¨ç½²

æˆ‘ä»¬ä½¿ç”¨ [LMDeploy](https://github.com/InternLM/LMDeploy) å®Œæˆ InternLM çš„ä¸€é”®éƒ¨ç½²ã€‚

### æ¨ç†

é€šè¿‡ `pip install lmdeploy` å®‰è£… LMDeploy ä¹‹åï¼Œåªéœ€ 4 è¡Œä»£ç ï¼Œå°±å¯ä»¥å®ç°ç¦»çº¿æ‰¹å¤„ç†ï¼š

```python
from lmdeploy import pipeline
pipe = pipeline("internlm/internlm2_5-7b-chat")
response = pipe(["Hi, pls intro yourself", "Shanghai is"])
print(response)
```

ä¸ºäº†å‡å°‘å†…å­˜å ç”¨ï¼Œæˆ‘ä»¬æä¾›äº†4ä½é‡åŒ–æ¨¡å‹ [internlm2_5-7b-chat-4bit](https://huggingface.co/internlm/internlm2_5-7b-chat-4bit)ã€‚å¯ä»¥æŒ‰ç…§å¦‚ä¸‹æ–¹å¼æ¨ç†è¯¥æ¨¡å‹ï¼š

```python
from lmdeploy import pipeline
pipe = pipeline("internlm/internlm2_5-7b-chat-4bit")
response = pipe(["Hi, pls intro yourself", "Shanghai is"])
print(response)
```

æ­¤å¤–ï¼Œå¯ä»¥åŒæ­¥å¼€å¯ 8bit æˆ–è€… 4bit KV åœ¨çº¿é‡åŒ–åŠŸèƒ½ï¼š

```python
from lmdeploy import pipeline, TurbomindEngineConfig
pipe = pipeline("internlm/internlm2_5-7b-chat-4bit",
                backend_config=TurbomindEngineConfig(quant_policy=8))
response = pipe(["Hi, pls intro yourself", "Shanghai is"])
print(response)
```

æ›´å¤šä½¿ç”¨æ¡ˆä¾‹å¯å‚è€ƒ[éƒ¨ç½²æŒ‡å—](./chat/lmdeploy.md)ï¼Œè¯¦ç»†çš„éƒ¨ç½²æ•™ç¨‹åˆ™å¯åœ¨[è¿™é‡Œ](https://github.com/InternLM/LMDeploy)æ‰¾åˆ°ã€‚

### 1ç™¾ä¸‡å­—è¶…é•¿ä¸Šä¸‹æ–‡æ¨ç†

æ¿€æ´» LMDeploy çš„ Dynamic NTK èƒ½åŠ›ï¼Œå¯ä»¥è½»æ¾æŠŠ internlm2_5-7b-chat å¤–æ¨åˆ° 200K ä¸Šä¸‹æ–‡ã€‚

æ³¨æ„: 1M ä¸Šä¸‹æ–‡éœ€è¦ 4xA100-80Gã€‚

```python
from lmdeploy import pipeline, GenerationConfig, TurbomindEngineConfig

backend_config = TurbomindEngineConfig(
        rope_scaling_factor=2.5,
        session_len=1048576,  # 1M context length
        max_batch_size=1,
        cache_max_entry_count=0.7,
        tp=4)  # 4xA100-80G.
pipe = pipeline('internlm/internlm2_5-7b-chat-1m', backend_config=backend_config)
prompt = 'Use a long prompt to replace this sentence'
response = pipe(prompt)
print(response)
```

## æ™ºèƒ½ä½“

InternLM-2.5-Chat æ¨¡å‹æœ‰å‡ºè‰²çš„å·¥å…·è°ƒç”¨æ€§èƒ½å¹¶å…·æœ‰ä¸€å®šçš„é›¶æ ·æœ¬æ³›åŒ–èƒ½åŠ›ã€‚å®ƒæ”¯æŒä»ä¸Šç™¾ä¸ªç½‘é¡µä¸­æœé›†ä¿¡æ¯å¹¶è¿›è¡Œåˆ†æã€‚æ›´å¤šæ ·ä¾‹å¯ä»¥å‚è€ƒ  [agent ç›®å½•](./agent/).

## å¾®è°ƒ&è®­ç»ƒ

è¯·å‚è€ƒ[å¾®è°ƒæ•™ç¨‹](./finetune/)å°è¯•ç»­è®­æˆ–å¾®è°ƒ InternLM2ã€‚

**æ³¨æ„ï¼š** æœ¬é¡¹ç›®ä¸­çš„å…¨é‡è®­ç»ƒåŠŸèƒ½å·²ç»è¿ç§»åˆ°äº† [InternEvo](https://github.com/InternLM/InternEvo) ä»¥ä¾¿ç”¨æˆ·ä½¿ç”¨ã€‚InternEvo æä¾›äº†é«˜æ•ˆçš„é¢„è®­ç»ƒå’Œå¾®è°ƒåŸºå»ºç”¨äºè®­ç»ƒ InternLM ç³»åˆ—æ¨¡å‹ã€‚

## è¯„æµ‹

æˆ‘ä»¬ä½¿ç”¨ [OpenCompass](https://github.com/open-compass/opencompass) è¿›è¡Œæ¨¡å‹è¯„ä¼°ã€‚åœ¨ InternLM2.5 ä¸­ï¼Œæˆ‘ä»¬ä¸»è¦æ ‡å‡†å®¢è§‚è¯„ä¼°ã€é•¿æ–‡è¯„ä¼°ï¼ˆå¤§æµ·æé’ˆï¼‰ã€æ•°æ®æ±¡æŸ“è¯„ä¼°ã€æ™ºèƒ½ä½“è¯„ä¼°å’Œä¸»è§‚è¯„ä¼°ã€‚

### æ ‡å‡†å®¢è§‚è¯„æµ‹

è¯·æŒ‰ç…§ [OpenCompass æ•™ç¨‹](https://opencompass.readthedocs.io/zh-cn/latest/get_started/installation.html) è¿›è¡Œå®¢è§‚è¯„æµ‹ã€‚æˆ‘ä»¬é€šå¸¸åœ¨ Base æ¨¡å‹ä¸Šä½¿ç”¨ ppl è¿›è¡Œå¤šé¡¹é€‰æ‹©é¢˜è¯„æµ‹ï¼Œåœ¨ Chat æ¨¡å‹ä¸Šä½¿ç”¨ gen è¿›è¡Œæ‰€æœ‰é—®é¢˜çš„ç­”æ¡ˆç”Ÿæˆå’Œè¯„æµ‹ã€‚

### é•¿æ–‡è¯„ä¼°ï¼ˆå¤§æµ·æé’ˆï¼‰

æœ‰å…³ `å¤§æµ·æé’ˆ` è¯„ä¼°çš„æ•™ç¨‹ï¼Œè¯·å‚é˜… [æ–‡æ¡£](https://github.com/open-compass/opencompass/blob/main/docs/en/advanced_guides/needleinahaystack_eval.md) ä¸­çš„æ•™ç¨‹ã€‚

### æ•°æ®æ±¡æŸ“è¯„ä¼°

è¦äº†è§£æ›´å¤šå…³äºæ•°æ®æ±¡æŸ“è¯„ä¼°çš„ä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹ [æ±¡æŸ“è¯„ä¼°](https://opencompass.readthedocs.io/en/latest/advanced_guides/contamination_eval.html)ã€‚

### æ™ºèƒ½ä½“è¯„ä¼°

- è¦è¯„ä¼°å¤§æ¨¡å‹çš„å·¥å…·åˆ©ç”¨èƒ½åŠ›ï¼Œè¯·ä½¿ç”¨ [T-Eval](https://github.com/open-compass/T-Eval) è¿›è¡Œè¯„æµ‹ã€‚
- å¯¹äºä»£ç è§£é‡Šå™¨è¯„ä¼°ï¼Œè¯·ä½¿ç”¨ [gsm-8k-agent](https://github.com/open-compass/opencompass/blob/main/configs/datasets/gsm8k/gsm8k_agent_gen_be1606.py) æä¾›çš„é…ç½®è¿›è¡Œè¯„ä¼°ã€‚æ­¤å¤–ï¼Œæ‚¨è¿˜éœ€è¦å®‰è£… [Lagent](https://github.com/InternLM/lagent)ã€‚

### ä¸»è§‚è¯„ä¼°

- è¯·æŒ‰ç…§ [æ•™ç¨‹](https://opencompass.readthedocs.io/en/latest/advanced_guides/subjective_evaluation.html) è¿›è¡Œä¸»è§‚è¯„ä¼°ã€‚

## è´¡çŒ®

æˆ‘ä»¬æ„Ÿè°¢æ‰€æœ‰çš„è´¡çŒ®è€…ä¸ºæ”¹è¿›å’Œæå‡ InternLM æ‰€ä½œå‡ºçš„åŠªåŠ›ã€‚éå¸¸æ¬¢è¿ç¤¾åŒºç”¨æˆ·èƒ½å‚ä¸è¿›é¡¹ç›®ä¸­æ¥ã€‚è¯·å‚è€ƒè´¡çŒ®æŒ‡å—æ¥äº†è§£å‚ä¸é¡¹ç›®è´¡çŒ®çš„ç›¸å…³æŒ‡å¼•ã€‚

## è‡´è°¢

InternLM ä»£ç åº“æ˜¯ä¸€æ¬¾ç”±ä¸Šæµ·äººå·¥æ™ºèƒ½å®éªŒå®¤å’Œæ¥è‡ªä¸åŒé«˜æ ¡ã€ä¼ä¸šçš„ç ”å‘äººå‘˜å…±åŒå‚ä¸è´¡çŒ®çš„å¼€æºé¡¹ç›®ã€‚æˆ‘ä»¬æ„Ÿè°¢æ‰€æœ‰ä¸ºé¡¹ç›®æä¾›æ–°åŠŸèƒ½æ”¯æŒçš„è´¡çŒ®è€…ï¼Œä»¥åŠæä¾›å®è´µåé¦ˆæ„è§çš„ç”¨æˆ·ã€‚æˆ‘ä»¬å¸Œæœ›è¿™ä¸ªå·¥å…·ç®±å’ŒåŸºå‡†æµ‹è¯•å¯ä»¥ä¸ºç¤¾åŒºæä¾›çµæ´»é«˜æ•ˆçš„ä»£ç å·¥å…·ï¼Œä¾›ç”¨æˆ·å¾®è°ƒ InternLM å¹¶å¼€å‘è‡ªå·±çš„æ–°æ¨¡å‹ï¼Œä»è€Œä¸æ–­ä¸ºå¼€æºç¤¾åŒºæä¾›è´¡çŒ®ã€‚ç‰¹åˆ«é¸£è°¢ [flash-attention](https://github.com/HazyResearch/flash-attention) ä¸ [ColossalAI](https://github.com/hpcaitech/ColossalAI) ä¸¤é¡¹å¼€æºé¡¹ç›®ã€‚

## å¼€æºè®¸å¯è¯

æœ¬ä»“åº“çš„ä»£ç ä¾ç…§ Apache-2.0 åè®®å¼€æºã€‚æ¨¡å‹æƒé‡å¯¹å­¦æœ¯ç ”ç©¶å®Œå…¨å¼€æ”¾ï¼Œä¹Ÿå¯ç”³è¯·å…è´¹çš„å•†ä¸šä½¿ç”¨æˆæƒï¼ˆ[ç”³è¯·è¡¨](https://wj.qq.com/s2/12725412/f7c1/)ï¼‰ã€‚å…¶ä»–é—®é¢˜ä¸åˆä½œè¯·è”ç³» <internlm@pjlab.org.cn>ã€‚

## å¼•ç”¨

```
@misc{cai2024internlm2,
      title={InternLM2 Technical Report},
      author={Zheng Cai and Maosong Cao and Haojiong Chen and Kai Chen and Keyu Chen and Xin Chen and Xun Chen and Zehui Chen and Zhi Chen and Pei Chu and Xiaoyi Dong and Haodong Duan and Qi Fan and Zhaoye Fei and Yang Gao and Jiaye Ge and Chenya Gu and Yuzhe Gu and Tao Gui and Aijia Guo and Qipeng Guo and Conghui He and Yingfan Hu and Ting Huang and Tao Jiang and Penglong Jiao and Zhenjiang Jin and Zhikai Lei and Jiaxing Li and Jingwen Li and Linyang Li and Shuaibin Li and Wei Li and Yining Li and Hongwei Liu and Jiangning Liu and Jiawei Hong and Kaiwen Liu and Kuikun Liu and Xiaoran Liu and Chengqi Lv and Haijun Lv and Kai Lv and Li Ma and Runyuan Ma and Zerun Ma and Wenchang Ning and Linke Ouyang and Jiantao Qiu and Yuan Qu and Fukai Shang and Yunfan Shao and Demin Song and Zifan Song and Zhihao Sui and Peng Sun and Yu Sun and Huanze Tang and Bin Wang and Guoteng Wang and Jiaqi Wang and Jiayu Wang and Rui Wang and Yudong Wang and Ziyi Wang and Xingjian Wei and Qizhen Weng and Fan Wu and Yingtong Xiong and Chao Xu and Ruiliang Xu and Hang Yan and Yirong Yan and Xiaogui Yang and Haochen Ye and Huaiyuan Ying and Jia Yu and Jing Yu and Yuhang Zang and Chuyu Zhang and Li Zhang and Pan Zhang and Peng Zhang and Ruijie Zhang and Shuo Zhang and Songyang Zhang and Wenjian Zhang and Wenwei Zhang and Xingcheng Zhang and Xinyue Zhang and Hui Zhao and Qian Zhao and Xiaomeng Zhao and Fengzhe Zhou and Zaida Zhou and Jingming Zhuo and Yicheng Zou and Xipeng Qiu and Yu Qiao and Dahua Lin},
      year={2024},
      eprint={2403.17297},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
```
